<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Reconnaissance Hiragana - Whisper API</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      font-family: system-ui, sans-serif;
      text-align: center;
      padding: 2rem;
      max-width: 600px;
      margin: 0 auto;
    }
    button {
      font-size: 1.2rem;
      padding: 1rem 2rem;
      cursor: pointer;
      border: 2px solid #333;
      border-radius: 8px;
      background: #4CAF50;
      color: white;
      font-weight: bold;
      transition: all 0.3s;
    }
    button:hover:not(:disabled) {
      background: #45a049;
    }
    button:disabled {
      background-color: #ccc;
      border-color: #999;
      cursor: not-allowed;
    }
    #kana {
      font-size: 4rem;
      margin-top: 1.5rem;
      min-height: 5rem;
    }
    #raw {
      margin-top: 1rem;
      color: #666;
      font-size: 0.9rem;
    }
    #error {
      margin-top: 1rem;
      color: red;
      font-size: 1rem;
    }
    #audioSection {
      margin-top: 2rem;
      padding: 1.5rem;
      background: #f8f9fa;
      border-radius: 10px;
    }
    #audioSection.hidden {
      display: none;
    }
    audio {
      width: 100%;
      margin: 1rem 0;
    }
    #debug {
      margin-top: 2rem;
      padding: 1rem;
      background: #f5f5f5;
      border-radius: 8px;
      font-size: 0.85rem;
      text-align: left;
      max-height: 300px;
      overflow-y: auto;
    }
    .hint {
      background: #e3f2fd;
      padding: 1rem;
      border-radius: 8px;
      margin: 1rem 0;
      font-size: 0.9rem;
    }
    .recording {
      display: inline-block;
      width: 12px;
      height: 12px;
      border-radius: 50%;
      background: red;
      margin-right: 8px;
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.3; }
    }
  </style>
</head>
<body>
  <h1>üé§ Prononce un hiragana</h1>
  
  <div class="hint">
    üí° <strong>Version Whisper API (Cloud)</strong><br>
    ‚Ä¢ Fonctionne sur PC et smartphone<br>
    ‚Ä¢ Reconnaissance tr√®s pr√©cise<br>
    ‚Ä¢ Prononce un son japonais clairement
  </div>
  
  <button id="mic">üé§ Parler (3s)</button>
  <div id="kana">‚Äî</div>
  <div id="raw"></div>
  <div id="error"></div>
  
  <div id="audioSection" class="hidden">
    <h3>üîä Audio enregistr√©</h3>
    <audio id="audioPlayer" controls></audio>
  </div>
  
  <div id="debug"></div>

<script>
  const micBtn = document.getElementById("mic");
  const kanaDiv = document.getElementById("kana");
  const rawDiv = document.getElementById("raw");
  const errorDiv = document.getElementById("error");
  const debugDiv = document.getElementById("debug");

  let mediaRecorder = null;
  let audioChunks = [];
  const RECORDING_DURATION = 3000; // 3 secondes

  function addDebug(msg, isError = false) {
    const time = new Date().toLocaleTimeString();
    debugDiv.innerHTML += `<div style="color: ${isError ? 'red' : '#333'}">[${time}] ${msg}</div>`;
    debugDiv.scrollTop = debugDiv.scrollHeight;
  }

  addDebug("‚úÖ Script charg√© - Whisper API pr√™t");

  // Mapping hiragana
  const kanaMap = {
    "„ÅÇ": "„ÅÇ", "„ÅÑ": "„ÅÑ", "„ÅÜ": "„ÅÜ", "„Åà": "„Åà", "„Åä": "„Åä",
    "„Åã": "„Åã", "„Åç": "„Åç", "„Åè": "„Åè", "„Åë": "„Åë", "„Åì": "„Åì",
    "„Åï": "„Åï", "„Åó": "„Åó", "„Åô": "„Åô", "„Åõ": "„Åõ", "„Åù": "„Åù",
    "„Åü": "„Åü", "„Å°": "„Å°", "„Å§": "„Å§", "„Å¶": "„Å¶", "„Å®": "„Å®",
    "„Å™": "„Å™", "„Å´": "„Å´", "„Å¨": "„Å¨", "„Å≠": "„Å≠", "„ÅÆ": "„ÅÆ",
    "„ÅØ": "„ÅØ", "„Å≤": "„Å≤", "„Åµ": "„Åµ", "„Å∏": "„Å∏", "„Åª": "„Åª",
    "„Åæ": "„Åæ", "„Åø": "„Åø", "„ÇÄ": "„ÇÄ", "„ÇÅ": "„ÇÅ", "„ÇÇ": "„ÇÇ",
    "„ÇÑ": "„ÇÑ", "„ÇÜ": "„ÇÜ", "„Çà": "„Çà",
    "„Çâ": "„Çâ", "„Çä": "„Çä", "„Çã": "„Çã", "„Çå": "„Çå", "„Çç": "„Çç",
    "„Çè": "„Çè", "„Çí": "„Çí", "„Çì": "„Çì",
    "„Åå": "„Åå", "„Åé": "„Åé", "„Åê": "„Åê", "„Åí": "„Åí", "„Åî": "„Åî",
    "„Åñ": "„Åñ", "„Åò": "„Åò", "„Åö": "„Åö", "„Åú": "„Åú", "„Åû": "„Åû",
    "„Å†": "„Å†", "„Å¢": "„Å¢", "„Å•": "„Å•", "„Åß": "„Åß", "„Å©": "„Å©",
    "„Å∞": "„Å∞", "„Å≥": "„Å≥", "„Å∂": "„Å∂", "„Åπ": "„Åπ", "„Åº": "„Åº",
    "„Å±": "„Å±", "„Å¥": "„Å¥", "„Å∑": "„Å∑", "„Å∫": "„Å∫", "„ÅΩ": "„ÅΩ",
    // Romaji fallback
    "a": "„ÅÇ", "i": "„ÅÑ", "u": "„ÅÜ", "e": "„Åà", "o": "„Åä",
    "ka": "„Åã", "ki": "„Åç", "ku": "„Åè", "ke": "„Åë", "ko": "„Åì",
    "sa": "„Åï", "shi": "„Åó", "si": "„Åó", "su": "„Åô", "se": "„Åõ", "so": "„Åù",
    "ta": "„Åü", "chi": "„Å°", "ti": "„Å°", "tsu": "„Å§", "tu": "„Å§",
    "te": "„Å¶", "to": "„Å®",
    "na": "„Å™", "ni": "„Å´", "nu": "„Å¨", "ne": "„Å≠", "no": "„ÅÆ",
    "ha": "„ÅØ", "hi": "„Å≤", "fu": "„Åµ", "hu": "„Åµ", "he": "„Å∏", "ho": "„Åª",
    "ma": "„Åæ", "mi": "„Åø", "mu": "„ÇÄ", "me": "„ÇÅ", "mo": "„ÇÇ",
    "ya": "„ÇÑ", "yu": "„ÇÜ", "yo": "„Çà",
    "ra": "„Çâ", "ri": "„Çä", "ru": "„Çã", "re": "„Çå", "ro": "„Çç",
    "wa": "„Çè", "wo": "„Çí", "n": "„Çì"
  };

  // Fonction de reconnaissance Whisper via API
  async function recognizeWithWhisperAPI(audioBlob) {
    try {
      addDebug("ü§ñ Envoi vers Whisper API...");
      
      // Convertir le blob en base64
      const base64Audio = await blobToBase64(audioBlob);
      
      // Appel √† l'API Anthropic avec Whisper
      const response = await fetch("https://api.anthropic.com/v1/messages", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "anthropic-version": "2023-06-01"
        },
        body: JSON.stringify({
          model: "claude-sonnet-4-20250514",
          max_tokens: 1024,
          messages: [{
            role: "user",
            content: [
              {
                type: "document",
                source: {
                  type: "base64",
                  media_type: "audio/webm",
                  data: base64Audio
                }
              },
              {
                type: "text",
                text: "Transcribe this audio. It contains a single Japanese hiragana sound. Return ONLY the hiragana character or its romaji equivalent, nothing else."
              }
            ]
          }]
        })
      });

      if (!response.ok) {
        throw new Error(`API error: ${response.status}`);
      }

      const data = await response.json();
      const transcript = data.content[0].text.trim();
      
      addDebug(`‚úÖ API r√©ponse: "${transcript}"`);
      return transcript;
      
    } catch (error) {
      addDebug(`‚ùå Erreur API: ${error.message}`, true);
      throw error;
    }
  }

  // Convertir Blob en Base64
  function blobToBase64(blob) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        const base64 = reader.result.split(',')[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  // D√©marrer l'enregistrement
  async function startRecording() {
    try {
      addDebug("üé§ D√©but enregistrement");
      kanaDiv.innerHTML = '<span class="recording"></span>üéß √âcoute...';
      rawDiv.textContent = "";
      errorDiv.textContent = "";
      micBtn.disabled = true;
      micBtn.textContent = "√âcoute en cours...";
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      let mimeType = 'audio/webm';
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mimeType = 'audio/webm;codecs=opus';
      }
      
      addDebug(`Format: ${mimeType}`);
      
      mediaRecorder = new MediaRecorder(stream, { mimeType });
      audioChunks = [];
      
      mediaRecorder.ondataavailable = (event) => {
        audioChunks.push(event.data);
      };
      
      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach(track => track.stop());
        await processRecording();
      };
      
      mediaRecorder.start();
      
      setTimeout(() => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
          mediaRecorder.stop();
          addDebug("‚èπÔ∏è Enregistrement termin√©");
        }
      }, RECORDING_DURATION);
      
    } catch (error) {
      addDebug(`‚ùå Erreur enregistrement: ${error.message}`, true);
      errorDiv.textContent = `Erreur: ${error.message}`;
      micBtn.disabled = false;
      micBtn.textContent = "üé§ Parler (3s)";
      kanaDiv.textContent = "‚Äî";
    }
  }

  // Traiter l'enregistrement
  async function processRecording() {
    try {
      kanaDiv.textContent = "‚öôÔ∏è Analyse Whisper...";
      
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
      
      // Afficher le lecteur audio
      const audioPlayer = document.getElementById('audioPlayer');
      audioPlayer.src = URL.createObjectURL(audioBlob);
      document.getElementById('audioSection').classList.remove('hidden');
      
      // Reconnaissance via API
      const transcript = await recognizeWithWhisperAPI(audioBlob);
      
      rawDiv.textContent = `Reconnu : "${transcript}"`;
      
      // Chercher correspondance
      let found = false;
      const cleanTranscript = transcript.toLowerCase().trim();
      
      // Essai 1: Match direct
      if (kanaMap[cleanTranscript]) {
        kanaDiv.textContent = kanaMap[cleanTranscript];
        found = true;
        addDebug(`‚úÖ Match: "${cleanTranscript}" ‚Üí ${kanaMap[cleanTranscript]}`);
      }
      
      // Essai 2: Premi√®re lettre
      if (!found && cleanTranscript.length > 0) {
        const firstChar = cleanTranscript.charAt(0);
        if (kanaMap[firstChar]) {
          kanaDiv.textContent = kanaMap[firstChar];
          found = true;
          addDebug(`‚úÖ Match 1er char: "${firstChar}" ‚Üí ${kanaMap[firstChar]}`);
        }
      }
      
      // Essai 3: Chercher dans le texte
      if (!found) {
        for (const [key, value] of Object.entries(kanaMap)) {
          if (cleanTranscript.includes(key)) {
            kanaDiv.textContent = value;
            found = true;
            addDebug(`‚úÖ Match contient: "${key}" ‚Üí ${value}`);
            break;
          }
        }
      }
      
      if (!found) {
        kanaDiv.textContent = "‚ùì Pas reconnu";
        addDebug("‚ùå Aucune correspondance");
      }
      
    } catch (error) {
      addDebug(`‚ùå Erreur traitement: ${error.message}`, true);
      errorDiv.textContent = `‚ùå ${error.message}`;
      kanaDiv.textContent = "‚Äî";
    } finally {
      micBtn.disabled = false;
      micBtn.textContent = "üé§ Parler (3s)";
    }
  }

  micBtn.onclick = startRecording;
</script>
</body>
</html>
