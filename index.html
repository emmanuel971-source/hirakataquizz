<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <title>Quiz Kana - ML Audio</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      font-family: system-ui, sans-serif;
      text-align: center;
      padding: 2rem;
      max-width: 700px;
      margin: 0 auto;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
    }
    .container {
      background: white;
      padding: 2rem;
      border-radius: 20px;
      box-shadow: 0 20px 60px rgba(0,0,0,0.3);
    }
    h1 {
      color: #333;
      margin-bottom: 1rem;
    }
    .loading {
      font-size: 1.1rem;
      color: #666;
      margin: 2rem 0;
    }
    .progress {
      width: 100%;
      height: 30px;
      background: #f0f0f0;
      border-radius: 15px;
      overflow: hidden;
      margin: 1rem 0;
    }
    .progress-bar {
      height: 100%;
      background: linear-gradient(90deg, #4CAF50, #45a049);
      width: 0%;
      transition: width 0.3s;
      display: flex;
      align-items: center;
      justify-content: center;
      color: white;
      font-weight: bold;
    }
    button {
      font-size: 1.2rem;
      padding: 1rem 2rem;
      cursor: pointer;
      border: none;
      border-radius: 12px;
      background: #4CAF50;
      color: white;
      font-weight: bold;
      margin: 1rem;
      transition: all 0.3s;
    }
    button:hover:not(:disabled) {
      background: #45a049;
      transform: translateY(-2px);
    }
    button:disabled {
      background: #ccc;
      cursor: not-allowed;
    }
    button.listening {
      background: #f44336;
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.7; }
    }
    #kana {
      font-size: 8rem;
      margin: 2rem 0;
      color: #333;
      min-height: 10rem;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    #kana.success {
      color: #4CAF50;
      animation: pop 0.3s;
    }
    @keyframes pop {
      0% { transform: scale(1); }
      50% { transform: scale(1.2); }
      100% { transform: scale(1); }
    }
    #confidence {
      font-size: 1.1rem;
      color: #666;
      margin: 1rem 0;
    }
    .matches {
      margin: 1rem 0;
      padding: 1rem;
      background: #f5f5f5;
      border-radius: 8px;
      text-align: left;
    }
    .match-item {
      padding: 0.3rem;
      font-size: 0.9rem;
    }
    #debug {
      margin-top: 1rem;
      padding: 1rem;
      background: #f5f5f5;
      border-radius: 8px;
      font-size: 0.75rem;
      text-align: left;
      max-height: 150px;
      overflow-y: auto;
      font-family: monospace;
    }
    .error {
      color: #f44336;
      font-weight: bold;
      margin: 1rem;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üé§ Quiz Kana - ML Audio</h1>
    
    <div id="loading" class="loading">
      Chargement des r√©f√©rences audio...
      <div class="progress">
        <div class="progress-bar" id="progressBar">0%</div>
      </div>
    </div>
    
    <div id="mainInterface" style="display: none;">
      <p>Prononce un kana - le syst√®me compare avec les r√©f√©rences</p>
      <button id="recordBtn" disabled>Enregistrer (1s)</button>
      <div id="kana">‚Äî</div>
      <div id="confidence"></div>
      <div class="matches" id="matches"></div>
    </div>
    
    <div class="error" id="error"></div>
    <div id="debug"></div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0"></script>

<script>
  // üî• Tous les MP3 sont √† la racine
  const BASE_URL = "https://emmanuel971-source.github.io/hirakataquizz/";
  
  // Liste des hiraganas
  const allKana = [
    "„ÅÇ", "„ÅÑ", "„ÅÜ", "„Åà", "„Åä",
    "„Åã", "„Åç", "„Åè", "„Åë", "„Åì",
    "„Åï", "„Åó", "„Åô", "„Åõ", "„Åù",
    "„Åü", "„Å°", "„Å§", "„Å¶", "„Å®",
    "„Å™", "„Å´", "„Å¨", "„Å≠", "„ÅÆ",
    "„ÅØ", "„Å≤", "„Åµ", "„Å∏", "„Åª",
    "„Åæ", "„Åø", "„ÇÄ", "„ÇÅ", "„ÇÇ",
    "„ÇÑ", "„ÇÜ", "„Çà",
    "„Çâ", "„Çä", "„Çã", "„Çå", "„Çç",
    "„Çè", "„Çí", "„Çì",
    "„Åå", "„Åé", "„Åê", "„Åí", "„Åî",
    "„Åñ", "„Åò", "„Åö", "„Åú", "„Åû",
    "„Å†", "„Å¢", "„Å•", "„Åß", "„Å©",
    "„Å∞", "„Å≥", "„Å∂", "„Åπ", "„Åº",
    "„Å±", "„Å¥", "„Å∑", "„Å∫", "„ÅΩ"
  ];

  const recordBtn = document.getElementById("recordBtn");
  const kanaDiv = document.getElementById("kana");
  const confidenceDiv = document.getElementById("confidence");
  const matchesDiv = document.getElementById("matches");
  const errorDiv = document.getElementById("error");
  const debugDiv = document.getElementById("debug");
  const loadingDiv = document.getElementById("loading");
  const mainInterface = document.getElementById("mainInterface");
  const progressBar = document.getElementById("progressBar");

  let audioContext;
  let referenceFeatures = {};
  let isRecording = false;

  function addDebug(msg, isError = false) {
    const time = new Date().toLocaleTimeString();
    debugDiv.innerHTML += `<div style="color: ${isError ? 'red' : '#333'}">[${time}] ${msg}</div>`;
    debugDiv.scrollTop = debugDiv.scrollHeight;
  }

  addDebug("Initialisation...");

  // Fonction pour extraire les features audio (MFCC simplifi√©s)
  async function extractAudioFeatures(audioBuffer) {
    const audioData = audioBuffer.getChannelData(0);
    const sampleRate = audioBuffer.sampleRate;
    
    // Convertir en spectrogramme simplifi√©
    const fftSize = 2048;
    const hopSize = 512;
    const features = [];
    
    for (let i = 0; i < audioData.length - fftSize; i += hopSize) {
      const frame = audioData.slice(i, i + fftSize);
      const spectrum = computeSpectrum(frame);
      features.push(spectrum);
    }
    
    // Moyenne des features
    const avgFeatures = new Array(features[0].length).fill(0);
    for (let i = 0; i < features.length; i++) {
      for (let j = 0; j < features[i].length; j++) {
        avgFeatures[j] += features[i][j];
      }
    }
    return avgFeatures.map(v => v / features.length);
  }

  function computeSpectrum(frame) {
    // FFT simplifi√© - calculer l'√©nergie par bandes de fr√©quence
    const numBands = 20;
    const bandEnergy = new Array(numBands).fill(0);
    const bandSize = Math.floor(frame.length / numBands);
    
    for (let i = 0; i < numBands; i++) {
      let energy = 0;
      for (let j = 0; j < bandSize; j++) {
        const idx = i * bandSize + j;
        if (idx < frame.length) {
          energy += frame[idx] * frame[idx];
        }
      }
      bandEnergy[i] = Math.sqrt(energy / bandSize);
    }
    
    return bandEnergy;
  }

  // Similarit√© cosinus entre deux vecteurs
  function cosineSimilarity(a, b) {
    let dotProduct = 0;
    let normA = 0;
    let normB = 0;
    
    for (let i = 0; i < a.length; i++) {
      dotProduct += a[i] * b[i];
      normA += a[i] * a[i];
      normB += b[i] * b[i];
    }
    
    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
  }

  // Charger un fichier audio MP3
  async function loadAudioFile(url) {
    try {
      addDebug(`Chargement: ${url}`);
      const response = await fetch(url);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      const arrayBuffer = await response.arrayBuffer();
      return await audioContext.decodeAudioData(arrayBuffer);
    } catch (e) {
      addDebug(`Erreur ${url}: ${e.message}`, true);
      return null;
    }
  }

  // Charger toutes les r√©f√©rences
  async function loadReferences() {
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    addDebug(`Chargement de ${allKana.length} r√©f√©rences depuis ${BASE_URL}`);
    
    let loaded = 0;
    
    for (const kana of allKana) {
      const url = `${BASE_URL}${kana}.mp3`;
      const audioBuffer = await loadAudioFile(url);
      
      if (audioBuffer) {
        referenceFeatures[kana] = await extractAudioFeatures(audioBuffer);
        loaded++;
        addDebug(`‚úì ${kana} charg√© (${audioBuffer.duration.toFixed(2)}s)`);
        
        const progress = Math.round((loaded / allKana.length) * 100);
        progressBar.style.width = `${progress}%`;
        progressBar.textContent = `${progress}%`;
      } else {
        addDebug(`‚úó ${kana}.mp3 introuvable`, true);
      }
    }
    
    addDebug(`${loaded}/${allKana.length} r√©f√©rences charg√©es`);
    
    if (loaded > 0) {
      loadingDiv.style.display = "none";
      mainInterface.style.display = "block";
      recordBtn.disabled = false;
      addDebug("‚úì Pr√™t √† enregistrer !");
    } else {
      errorDiv.textContent = `‚ùå Aucun fichier trouv√© √† ${BASE_URL}`;
      addDebug("V√©rifie que les MP3 sont bien accessibles", true);
    }
  }

  // Enregistrer depuis le micro
  async function recordAudio(duration = 1000) {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      const chunks = [];
      
      mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
      
      return new Promise((resolve, reject) => {
        mediaRecorder.onstop = async () => {
          stream.getTracks().forEach(track => track.stop());
          const blob = new Blob(chunks, { type: 'audio/webm' });
          const arrayBuffer = await blob.arrayBuffer();
          try {
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            resolve(audioBuffer);
          } catch (e) {
            reject(e);
          }
        };
        
        mediaRecorder.start();
        addDebug("üé§ Enregistrement 1s...");
        
        setTimeout(() => {
          mediaRecorder.stop();
          addDebug("Analyse des features...");
        }, duration);
      });
    } catch (e) {
      addDebug(`Erreur micro: ${e.message}`, true);
      throw e;
    }
  }

  // Comparer avec les r√©f√©rences
  async function compareWithReferences(recordedFeatures) {
    const similarities = [];
    
    for (const [kana, features] of Object.entries(referenceFeatures)) {
      const similarity = cosineSimilarity(recordedFeatures, features);
      similarities.push({ kana, similarity });
    }
    
    // Trier par similarit√© d√©croissante
    similarities.sort((a, b) => b.similarity - a.similarity);
    
    return similarities;
  }

  // Bouton d'enregistrement
  recordBtn.onclick = async () => {
    if (isRecording) return;
    
    isRecording = true;
    recordBtn.disabled = true;
    recordBtn.classList.add("listening");
    recordBtn.textContent = "Enregistrement...";
    kanaDiv.textContent = "üé§";
    confidenceDiv.textContent = "";
    matchesDiv.innerHTML = "";
    
    try {
      const audioBuffer = await recordAudio(1000);
      const features = await extractAudioFeatures(audioBuffer);
      const results = await compareWithReferences(features);
      
      addDebug(`Top 3: ${results.slice(0, 3).map(r => `${r.kana}(${(r.similarity * 100).toFixed(0)}%)`).join(', ')}`);
      
      // Afficher le meilleur match
      const best = results[0];
      kanaDiv.textContent = best.kana;
      kanaDiv.classList.add("success");
      confidenceDiv.textContent = `Similarit√©: ${(best.similarity * 100).toFixed(0)}%`;
      
      // Afficher top 5
      matchesDiv.innerHTML = "<strong>Top 5 correspondances:</strong><br>" +
        results.slice(0, 5).map((r, i) => 
          `<div class="match-item">${i + 1}. ${r.kana} - ${(r.similarity * 100).toFixed(0)}%</div>`
        ).join('');
      
      setTimeout(() => {
        kanaDiv.classList.remove("success");
      }, 1000);
      
    } catch (e) {
      errorDiv.textContent = `‚ùå ${e.message}`;
      addDebug(`Erreur: ${e.message}`, true);
    } finally {
      isRecording = false;
      recordBtn.disabled = false;
      recordBtn.classList.remove("listening");
      recordBtn.textContent = "Enregistrer (1s)";
    }
  };

  // D√©marrage
  window.onload = () => {
    loadReferences();
  };
</script>
</body>
</html>
