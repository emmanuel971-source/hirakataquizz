import React, { useState, useRef } from 'react';

export default function HiraganaRecognition() {
  const [status, setStatus] = useState('idle');
  const [recognizedKana, setRecognizedKana] = useState('â€”');
  const [transcription, setTranscription] = useState('');
  const [audioUrl, setAudioUrl] = useState(null);
  const [debugLog, setDebugLog] = useState([]);
  
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const RECORDING_DURATION = 2000; // 2 secondes

  // Mapping hiragana complet
  const kanaMap = {
    // Hiragana direct
    "ã‚": "ã‚", "ã„": "ã„", "ã†": "ã†", "ãˆ": "ãˆ", "ãŠ": "ãŠ",
    "ã‹": "ã‹", "ã": "ã", "ã": "ã", "ã‘": "ã‘", "ã“": "ã“",
    "ã•": "ã•", "ã—": "ã—", "ã™": "ã™", "ã›": "ã›", "ã": "ã",
    "ãŸ": "ãŸ", "ã¡": "ã¡", "ã¤": "ã¤", "ã¦": "ã¦", "ã¨": "ã¨",
    "ãª": "ãª", "ã«": "ã«", "ã¬": "ã¬", "ã­": "ã­", "ã®": "ã®",
    "ã¯": "ã¯", "ã²": "ã²", "ãµ": "ãµ", "ã¸": "ã¸", "ã»": "ã»",
    "ã¾": "ã¾", "ã¿": "ã¿", "ã‚€": "ã‚€", "ã‚": "ã‚", "ã‚‚": "ã‚‚",
    "ã‚„": "ã‚„", "ã‚†": "ã‚†", "ã‚ˆ": "ã‚ˆ",
    "ã‚‰": "ã‚‰", "ã‚Š": "ã‚Š", "ã‚‹": "ã‚‹", "ã‚Œ": "ã‚Œ", "ã‚": "ã‚",
    "ã‚": "ã‚", "ã‚’": "ã‚’", "ã‚“": "ã‚“",
    "ãŒ": "ãŒ", "ã": "ã", "ã": "ã", "ã’": "ã’", "ã”": "ã”",
    "ã–": "ã–", "ã˜": "ã˜", "ãš": "ãš", "ãœ": "ãœ", "ã": "ã",
    "ã ": "ã ", "ã¢": "ã¢", "ã¥": "ã¥", "ã§": "ã§", "ã©": "ã©",
    "ã°": "ã°", "ã³": "ã³", "ã¶": "ã¶", "ã¹": "ã¹", "ã¼": "ã¼",
    "ã±": "ã±", "ã´": "ã´", "ã·": "ã·", "ãº": "ãº", "ã½": "ã½",
    // Romaji
    "a": "ã‚", "i": "ã„", "u": "ã†", "e": "ãˆ", "o": "ãŠ",
    "ka": "ã‹", "ki": "ã", "ku": "ã", "ke": "ã‘", "ko": "ã“",
    "sa": "ã•", "shi": "ã—", "si": "ã—", "su": "ã™", "se": "ã›", "so": "ã",
    "ta": "ãŸ", "chi": "ã¡", "ti": "ã¡", "tsu": "ã¤", "tu": "ã¤",
    "te": "ã¦", "to": "ã¨",
    "na": "ãª", "ni": "ã«", "nu": "ã¬", "ne": "ã­", "no": "ã®",
    "ha": "ã¯", "hi": "ã²", "fu": "ãµ", "hu": "ãµ", "he": "ã¸", "ho": "ã»",
    "ma": "ã¾", "mi": "ã¿", "mu": "ã‚€", "me": "ã‚", "mo": "ã‚‚",
    "ya": "ã‚„", "yu": "ã‚†", "yo": "ã‚ˆ",
    "ra": "ã‚‰", "ri": "ã‚Š", "ru": "ã‚‹", "re": "ã‚Œ", "ro": "ã‚",
    "wa": "ã‚", "wo": "ã‚’", "n": "ã‚“"
  };

  const addLog = (msg, isError = false) => {
    const time = new Date().toLocaleTimeString();
    setDebugLog(prev => [...prev, { time, msg, isError }]);
  };

  const startRecording = async () => {
    try {
      setStatus('recording');
      setRecognizedKana('ğŸ§');
      setTranscription('');
      setAudioUrl(null);
      setDebugLog([]);
      addLog('ğŸ¤ DÃ©but enregistrement');

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 48000
        }
      });

      let mimeType = 'audio/webm';
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mimeType = 'audio/webm;codecs=opus';
      }

      addLog(`Format: ${mimeType}`);

      mediaRecorderRef.current = new MediaRecorder(stream, { 
        mimeType,
        audioBitsPerSecond: 128000
      });
      audioChunksRef.current = [];

      mediaRecorderRef.current.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      mediaRecorderRef.current.onstop = async () => {
        stream.getTracks().forEach(track => track.stop());
        await processRecording();
      };

      mediaRecorderRef.current.start();

      setTimeout(() => {
        if (mediaRecorderRef.current?.state === 'recording') {
          mediaRecorderRef.current.stop();
          addLog('â¹ï¸ Enregistrement terminÃ©');
        }
      }, RECORDING_DURATION);

    } catch (error) {
      addLog(`âŒ Erreur: ${error.message}`, true);
      setStatus('error');
      setRecognizedKana('â€”');
    }
  };

  const processRecording = async () => {
    try {
      setStatus('processing');
      setRecognizedKana('âš™ï¸');
      addLog('Traitement audio...');

      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      const url = URL.createObjectURL(audioBlob);
      setAudioUrl(url);

      addLog('ğŸ¤– Appel Whisper via Claude API...');

      // UTILISATION DE L'API WHISPER INTÃ‰GRÃ‰E DANS CLAUDE
      const result = await window.recognizeWithWhisper(audioBlob);
      
      addLog(`âœ… Transcription: "${result}"`);
      setTranscription(result);

      // Chercher correspondance
      const cleanResult = result.toLowerCase().trim();
      let found = false;

      // Essai 1: Match direct
      if (kanaMap[cleanResult]) {
        setRecognizedKana(kanaMap[cleanResult]);
        found = true;
        addLog(`âœ… Match direct: "${cleanResult}" â†’ ${kanaMap[cleanResult]}`);
      }

      // Essai 2: PremiÃ¨re lettre/caractÃ¨re
      if (!found && cleanResult.length > 0) {
        const firstChar = cleanResult.charAt(0);
        if (kanaMap[firstChar]) {
          setRecognizedKana(kanaMap[firstChar]);
          found = true;
          addLog(`âœ… Match 1er caractÃ¨re: "${firstChar}" â†’ ${kanaMap[firstChar]}`);
        }
      }

      // Essai 3: Contient un hiragana connu
      if (!found) {
        for (const [key, value] of Object.entries(kanaMap)) {
          if (cleanResult.includes(key) && key.length > 1) {
            setRecognizedKana(value);
            found = true;
            addLog(`âœ… Match contient: "${key}" â†’ ${value}`);
            break;
          }
        }
      }

      if (!found) {
        setRecognizedKana('â“');
        addLog('âŒ Aucune correspondance trouvÃ©e');
      }

      setStatus('ready');

    } catch (error) {
      addLog(`âŒ Erreur Whisper: ${error.message}`, true);
      setStatus('error');
      setRecognizedKana('â€”');
    }
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-100 p-8">
      <div className="max-w-2xl mx-auto bg-white rounded-2xl shadow-2xl p-8">
        {/* Header */}
        <div className="text-center mb-8">
          <h1 className="text-4xl font-bold text-indigo-600 mb-2">
            ğŸ¤ Reconnaissance Hiragana
          </h1>
          <p className="text-gray-600">Version Whisper AI - Artifact Claude</p>
        </div>

        {/* Hint */}
        <div className="bg-blue-50 border-l-4 border-blue-500 p-4 mb-6 rounded">
          <p className="text-sm text-gray-700">
            ğŸ’¡ <strong>Comment Ã§a marche :</strong><br/>
            â€¢ Clique sur "Parler" et prononce un hiragana (ex: ã‚, ã‹, ã—)<br/>
            â€¢ L'enregistrement dure 2 secondes<br/>
            â€¢ Whisper AI reconnaÃ®tra le son isolÃ© !
          </p>
        </div>

        {/* Bouton principal */}
        <div className="text-center mb-6">
          <button
            onClick={startRecording}
            disabled={status === 'recording' || status === 'processing'}
            className="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-4 px-8 rounded-xl text-xl transition-all transform hover:scale-105 disabled:bg-gray-400 disabled:cursor-not-allowed disabled:transform-none"
          >
            {status === 'recording' && 'ğŸ¤ Ã‰coute... (2s)'}
            {status === 'processing' && 'âš™ï¸ Analyse Whisper...'}
            {(status === 'idle' || status === 'ready' || status === 'error') && 'ğŸ¤ Parler'}
          </button>
        </div>

        {/* RÃ©sultat principal */}
        <div className="bg-gradient-to-r from-indigo-50 to-purple-50 rounded-xl p-8 mb-6 text-center border-2 border-indigo-200">
          <div className="text-8xl mb-4 font-bold">
            {recognizedKana}
          </div>
          {transcription && (
            <div className="text-gray-600 text-lg">
              Transcription : <span className="font-semibold">"{transcription}"</span>
            </div>
          )}
        </div>

        {/* Lecteur audio */}
        {audioUrl && (
          <div className="bg-gray-50 rounded-xl p-6 mb-6">
            <h3 className="font-semibold text-gray-700 mb-3">ğŸ”Š Audio enregistrÃ©</h3>
            <audio src={audioUrl} controls className="w-full" />
          </div>
        )}

        {/* Debug log */}
        {debugLog.length > 0 && (
          <div className="bg-gray-900 text-green-400 rounded-xl p-4 font-mono text-sm max-h-60 overflow-y-auto">
            <div className="font-bold text-green-300 mb-2">ğŸ“‹ Debug Log</div>
            {debugLog.map((log, i) => (
              <div key={i} className={log.isError ? 'text-red-400' : 'text-green-400'}>
                [{log.time}] {log.msg}
              </div>
            ))}
          </div>
        )}

        {/* Info technique */}
        <div className="mt-6 text-center text-sm text-gray-500">
          <p>âœ¨ Utilise Whisper AI via l'API Claude</p>
          <p>ğŸš€ Fonctionne sur PC et smartphone</p>
        </div>
      </div>
    </div>
  );
}
