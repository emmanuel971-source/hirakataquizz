<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üé§ Test Audio - Whisper Recognition</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            padding: 40px;
            max-width: 600px;
            width: 100%;
        }
        
        h1 {
            text-align: center;
            color: #667eea;
            margin-bottom: 10px;
            font-size: 2em;
        }
        
        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 0.9em;
        }
        
        .section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 15px;
            margin-bottom: 20px;
        }
        
        .section h3 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.2em;
        }
        
        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-size: 1.1em;
            font-weight: bold;
        }
        
        .status.idle {
            background: #e7e7e7;
            color: #333;
        }
        
        .status.loading {
            background: #fff3cd;
            color: #856404;
        }
        
        .status.recording {
            background: #d1ecf1;
            color: #0c5460;
        }
        
        .status.processing {
            background: #fff3cd;
            color: #856404;
        }
        
        .status.ready {
            background: #d4edda;
            color: #155724;
        }
        
        .status.success {
            background: #d4edda;
            color: #155724;
        }
        
        .status.error {
            background: #f8d7da;
            color: #721c24;
        }
        
        button {
            background: #667eea;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 1.1em;
            border-radius: 10px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s;
            width: 100%;
            margin-top: 10px;
        }
        
        button:hover:not(:disabled) {
            background: #764ba2;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }
        
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        
        button.secondary {
            background: #6c757d;
        }
        
        button.secondary:hover:not(:disabled) {
            background: #5a6268;
        }
        
        button.success {
            background: #28a745;
        }
        
        button.success:hover:not(:disabled) {
            background: #218838;
        }
        
        .timer {
            text-align: center;
            font-size: 3em;
            font-weight: bold;
            color: #667eea;
            margin: 20px 0;
        }
        
        .timer.warning {
            color: #dc3545;
            animation: pulse 0.5s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
        
        .debug-info {
            font-family: monospace;
            font-size: 0.85em;
            color: #666;
            line-height: 1.6;
        }
        
        .debug-line {
            margin: 5px 0;
        }
        
        .hidden {
            display: none;
        }
        
        audio {
            width: 100%;
            margin: 10px 0;
        }
        
        .select-wrapper {
            margin-bottom: 15px;
        }
        
        select {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 1em;
            background: white;
            cursor: pointer;
        }
        
        select:focus {
            outline: none;
            border-color: #667eea;
        }
        
        .result-box {
            background: white;
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 15px;
            margin-top: 15px;
            text-align: center;
        }
        
        .result-box .label {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 5px;
        }
        
        .result-box .value {
            font-size: 2em;
            font-weight: bold;
            color: #667eea;
        }
        
        .progress-bar {
            width: 100%;
            height: 20px;
            background: #e0e0e0;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Test Whisper AI</h1>
        <p class="subtitle">Reconnaissance vocale avec Whisper (offline)</p>
        
        <!-- Status -->
        <div id="statusDisplay" class="status loading">
            ‚è≥ Chargement du mod√®le Whisper...
        </div>
        
        <!-- Progress bar pour le chargement -->
        <div id="loadingSection">
            <div class="progress-bar">
                <div id="progressFill" class="progress-fill"></div>
            </div>
            <div class="debug-info" style="text-align: center;">
                <div id="loadingText">Initialisation...</div>
            </div>
        </div>
        
        <!-- S√©lection du suffixe -->
        <div class="section">
            <h3>1Ô∏è‚É£ Choisir un mot</h3>
            <div class="select-wrapper">
                <select id="suffixSelect">
                    <option value="„ÇÅ" data-word="„ÅÇ„ÇÅ" data-romaji="ame">„ÅÇ„ÇÅ - /ame/ (pluie)</option>
                    <option value="„Åà" data-word="„ÅÑ„Åà" data-romaji="ie">„ÅÑ„Åà - /ie/ (maison)</option>
                    <option value="„Åø" data-word="„ÅÜ„Åø" data-romaji="umi">„ÅÜ„Åø - /umi/ (mer)</option>
                    <option value="„Åç" data-word="„Åà„Åç" data-romaji="eki">„Åà„Åç - /eki/ (gare)</option>
                    <option value="„Å°„ÇÉ" data-word="„Åä„Å°„ÇÉ" data-romaji="ocha">„Åä„Å°„ÇÉ - /ocha/ (th√©)</option>
                </select>
            </div>
            <div class="debug-info">
                <div class="debug-line">Mot attendu: <span id="debugExpectedWord">„ÅÇ„ÇÅ</span></div>
                <div class="debug-line">Romaji: <span id="debugRomaji">ame</span></div>
                <div class="debug-line">Suffixe: <span id="debugSuffix">„ÇÅ</span></div>
                <div class="debug-line">Charg√©s: <span id="debugLoaded">-</span></div>
            </div>
        </div>
        
        <!-- Enregistrement -->
        <div class="section">
            <h3>2Ô∏è‚É£ Enregistrer (3 secondes)</h3>
            <div id="timerDisplay" class="timer hidden">3</div>
            <button id="recordBtn" onclick="startRecording()" disabled>üé§ Commencer l'enregistrement</button>
            <div class="debug-info">
                <div class="debug-line">√âtat: <span id="debugRecording">-</span></div>
                <div class="debug-line">Dur√©e brute: <span id="debugDuration">-</span></div>
                <div class="debug-line">Dur√©e nettoy√©e: <span id="debugTrimmedDuration">-</span></div>
            </div>
        </div>
        
        <!-- Concat√©nation -->
        <div class="section">
            <h3>3Ô∏è‚É£ Concat√©nation</h3>
            <div class="debug-info">
                <div class="debug-line">Normalisation: <span id="debugNormalization">-</span></div>
                <div class="debug-line">Crossfade: <span id="debugCrossfade">-</span></div>
                <div class="debug-line">Dur√©e finale: <span id="debugFinalDuration">-</span></div>
            </div>
            <div id="audioPlayerSection" class="hidden">
                <audio id="audioPlayer" controls></audio>
                <button class="success" onclick="downloadAudio()">‚¨áÔ∏è T√©l√©charger WAV</button>
            </div>
        </div>
        
        <!-- Reconnaissance vocale Whisper -->
        <div class="section">
            <h3>4Ô∏è‚É£ Reconnaissance Whisper AI</h3>
            <div class="debug-info">
                <div class="debug-line">√âtat: <span id="debugRecognition">-</span></div>
            </div>
            <div id="recognitionResult" class="hidden">
                <div class="result-box">
                    <div class="label">R√©sultat d√©tect√© :</div>
                    <div class="value" id="recognizedText">-</div>
                </div>
                <div class="result-box" style="margin-top: 10px;">
                    <div class="label">Comparaison :</div>
                    <div class="value" id="comparisonResult" style="font-size: 1.5em;">-</div>
                </div>
            </div>
        </div>
        
        <button class="secondary" onclick="resetTest()">üîÑ Recommencer</button>
    </div>

    <!-- Charger Transformers.js -->
    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';
        
        // Configuration
        env.allowLocalModels = false;
        
        // Variables globales
        window.whisperPipeline = null;
        window.isWhisperReady = false;
        
        // Charger le mod√®le Whisper
        async function loadWhisper() {
            try {
                document.getElementById('loadingText').textContent = 
                    'T√©l√©chargement du mod√®le Whisper (tiny) - ~75MB...';
                document.getElementById('progressFill').style.width = '10%';
                
                // Utiliser le mod√®le "tiny" pour le japonais
                window.whisperPipeline = await pipeline(
                    'automatic-speech-recognition',
                    'Xenova/whisper-tiny',
                    {
                        progress_callback: (progress) => {
                            if (progress.status === 'progress') {
                                const percent = Math.round((progress.loaded / progress.total) * 100);
                                document.getElementById('progressFill').style.width = percent + '%';
                                document.getElementById('loadingText').textContent = 
                                    `T√©l√©chargement: ${percent}%`;
                            }
                        }
                    }
                );
                
                document.getElementById('progressFill').style.width = '100%';
                document.getElementById('loadingText').textContent = '‚úÖ Mod√®le charg√© !';
                document.getElementById('loadingSection').classList.add('hidden');
                document.getElementById('statusDisplay').className = 'status idle';
                document.getElementById('statusDisplay').textContent = '‚úÖ Pr√™t √† enregistrer !';
                document.getElementById('recordBtn').disabled = false;
                
                window.isWhisperReady = true;
                console.log('‚úÖ Whisper pr√™t');
                
            } catch (error) {
                console.error('Erreur chargement Whisper:', error);
                document.getElementById('statusDisplay').className = 'status error';
                document.getElementById('statusDisplay').textContent = 
                    '‚ùå Erreur de chargement: ' + error.message;
            }
        }
        
        // Fonction de reconnaissance accessible globalement
// Remplace la fonction recognizeWithWhisper par celle-ci dans la section <script type="module"> :

window.recognizeWithWhisper = async function(audioBlob) {
    if (!window.isWhisperReady) {
        throw new Error('Whisper pas encore charg√©');
    }
    
    try {
        // Convertir le blob en ArrayBuffer
        const arrayBuffer = await audioBlob.arrayBuffer();
        
        // IMPORTANT: Cr√©er un AudioContext SANS sp√©cifier le sampleRate
        // Le navigateur choisira automatiquement le bon selon le device
        let audioContext;
        try {
            audioContext = new AudioContext();
        } catch (e) {
            // Fallback pour les anciens navigateurs
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        
        // Resample √† 16kHz pour Whisper
        const targetSampleRate = 16000;
        let audioData;
        
        if (audioBuffer.sampleRate === targetSampleRate) {
            // Pas besoin de resampling
            audioData = audioBuffer.getChannelData(0);
        } else {
            // Resampling n√©cessaire
            const offlineContext = new OfflineAudioContext(
                1,
                audioBuffer.duration * targetSampleRate,
                targetSampleRate
            );
            
            const source = offlineContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(offlineContext.destination);
            source.start();
            
            const resampledBuffer = await offlineContext.startRendering();
            audioData = resampledBuffer.getChannelData(0);
        }
        
        // Fermer le contexte pour lib√©rer les ressources
        await audioContext.close();
        
        // Lancer la transcription
        const result = await window.whisperPipeline(audioData, {
            language: 'japanese',
            task: 'transcribe'
        });
        
        return result.text;
        
    } catch (error) {
        console.error('Erreur reconnaissance:', error);
        throw error;
    }
};
        
        // D√©marrer le chargement
        loadWhisper();
    </script>

    <script>
        // Configuration
        const RECORDING_DURATION = 2000;
        const SILENCE_THRESHOLD = 0.01;
        const CROSSFADE_DURATION = 0.01;
        const AUDIO_BASE_URL = 'https://emmanuel971-source.github.io/hirakataquizz/';
        
        // Variables globales
        let audioContext;
        let mediaRecorder;
        let audioChunks = [];
        let suffixBuffers = {};
        let lastConcatenatedBlob = null;
        
        const SUFFIXES = ['„ÇÅ', '„Åà', '„Åø', '„Åç', '„Å°„ÇÉ'];
        
        // Initialisation des suffixes
// Remplace aussi la fonction init() pour l'AudioContext principal :

async function init() {
    try {
        // Ne pas sp√©cifier de sampleRate, laisser le navigateur choisir
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        console.log('AudioContext sampleRate:', audioContext.sampleRate);
        await loadAllSuffixes();
    } catch (error) {
        console.error('Erreur init:', error);
    }
}
        async function loadAllSuffixes() {
            let loaded = 0;
            
            for (const suffix of SUFFIXES) {
                try {
                    const url = AUDIO_BASE_URL + encodeURIComponent(suffix) + '.mp3';
                    const response = await fetch(url);
                    if (!response.ok) throw new Error(`HTTP ${response.status}`);
                    const arrayBuffer = await response.arrayBuffer();
                    suffixBuffers[suffix] = await audioContext.decodeAudioData(arrayBuffer);
                    loaded++;
                    console.log(`‚úÖ Suffixe ${suffix} charg√©`);
                    document.getElementById('debugLoaded').textContent = `${loaded}/${SUFFIXES.length}`;
                } catch (error) {
                    console.error(`‚ùå Erreur chargement ${suffix}:`, error);
                }
            }
            
            document.getElementById('debugLoaded').textContent = `${loaded}/${SUFFIXES.length} charg√©s`;
        }
        
      // Remplace la fonction startRecording() par celle-ci :

async function startRecording() {
    try {
        updateStatus('recording', 'üé§ Enregistrement...');
        document.getElementById('recordBtn').disabled = true;
        document.getElementById('debugRecording').textContent = 'En cours...';
        document.getElementById('audioPlayerSection').classList.add('hidden');
        document.getElementById('recognitionResult').classList.add('hidden');
        
        // Reset debug
        document.getElementById('debugNormalization').textContent = '-';
        document.getElementById('debugCrossfade').textContent = '-';
        document.getElementById('debugFinalDuration').textContent = '-';
        document.getElementById('debugRecognition').textContent = '-';
        
        // Timer
        const timerEl = document.getElementById('timerDisplay');
        timerEl.classList.remove('hidden', 'warning');
        let countdown = 3;
        timerEl.textContent = countdown;
        
        const timerInterval = setInterval(() => {
            countdown--;
            timerEl.textContent = countdown;
            if (countdown <= 1) timerEl.classList.add('warning');
            if (countdown <= 0) {
                clearInterval(timerInterval);
                timerEl.classList.add('hidden');
                timerEl.classList.remove('warning');
            }
        }, 1000);
        
        // Configuration audio optimis√©e
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true,
                sampleRate: 48000  // Sample rate √©lev√© pour meilleure qualit√©
            }
        });
        
        // D√©tecter le meilleur format MIME support√©
        let mimeType = 'audio/webm';
        if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
            mimeType = 'audio/webm;codecs=opus';
        } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
            mimeType = 'audio/mp4';
        } else if (MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
            mimeType = 'audio/ogg;codecs=opus';
        }
        
        console.log('Format utilis√©:', mimeType);
        
        mediaRecorder = new MediaRecorder(stream, { 
            mimeType: mimeType,
            audioBitsPerSecond: 128000  // Haute qualit√©
        });
        audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
        };
        
        mediaRecorder.onstop = async () => {
            stream.getTracks().forEach(track => track.stop());
            await processRecording();
        };
        
        mediaRecorder.start();
        
        setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        }, RECORDING_DURATION);
        
    } catch (error) {
        console.error('Erreur enregistrement:', error);
        updateStatus('error', '‚ùå Erreur: ' + error.message);
        document.getElementById('recordBtn').disabled = false;
    }
}
        
        async function processRecording() {
            try {
                updateStatus('processing', '‚öôÔ∏è Traitement...');
                document.getElementById('debugRecording').textContent = 'Traitement...';
                
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                const arrayBuffer = await audioBlob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                document.getElementById('debugDuration').textContent = 
                    audioBuffer.duration.toFixed(2) + 's';
                
                const trimmedBuffer = trimSilence(audioBuffer);
                
                document.getElementById('debugTrimmedDuration').textContent = 
                    trimmedBuffer.duration.toFixed(2) + 's';
                
                document.getElementById('debugRecording').textContent = '‚úÖ Nettoy√©';
                
                await concatenateWithSuffix(trimmedBuffer);
                
            } catch (error) {
                console.error('Erreur traitement:', error);
                updateStatus('error', '‚ùå Erreur: ' + error.message);
                document.getElementById('recordBtn').disabled = false;
            }
        }
        
      function trimSilence(buffer) {
    const channelData = buffer.getChannelData(0);
    const sampleRate = buffer.sampleRate;
    const threshold = 0.005;
    
    // Trouver le PREMIER son
    let start = 0;
    for (let i = 0; i < channelData.length; i++) {
        if (Math.abs(channelData[i]) > threshold) {
            start = Math.max(0, i - Math.floor(0.05 * sampleRate));
            break;
        }
    }
    
    // Trouver o√π le son s'ARR√äTE (premier long silence)
    let end = start;
    let silentSamples = 0;
    const maxSilence = Math.floor(0.3 * sampleRate); // 300ms de silence max
    
    for (let i = start; i < channelData.length; i++) {
        if (Math.abs(channelData[i]) > threshold) {
            silentSamples = 0;
            end = i;
        } else {
            silentSamples++;
            if (silentSamples > maxSilence) {
                // Trop de silence, on coupe ici
                break;
            }
        }
    }
    
    // Ajouter une petite marge √† la fin
    end = Math.min(channelData.length - 1, end + Math.floor(0.05 * sampleRate));
    
    if (start >= end) {
        console.warn('Aucun son d√©tect√©');
        return buffer;
    }
    
    const trimmedLength = end - start + 1;
    console.log('Trim:', {
        original: (buffer.length / sampleRate).toFixed(2) + 's',
        trimmed: (trimmedLength / sampleRate).toFixed(2) + 's',
        removed: ((buffer.length - trimmedLength) / sampleRate).toFixed(2) + 's'
    });
    
    const trimmedBuffer = audioContext.createBuffer(
        buffer.numberOfChannels,
        trimmedLength,
        sampleRate
    );
    
    for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
        const sourceData = buffer.getChannelData(channel);
        const targetData = trimmedBuffer.getChannelData(channel);
        targetData.set(sourceData.slice(start, end + 1));
    }
    
    return trimmedBuffer;
}
        
        function normalizeBuffer(buffer) {
            let max = 0;
            for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
                const data = buffer.getChannelData(channel);
                for (let i = 0; i < data.length; i++) {
                    max = Math.max(max, Math.abs(data[i]));
                }
            }
            
            const targetLevel = 0.8;
            const gain = max > 0 ? targetLevel / max : 1;
            
            const normalized = audioContext.createBuffer(
                buffer.numberOfChannels,
                buffer.length,
                buffer.sampleRate
            );
            
            for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
                const sourceData = buffer.getChannelData(channel);
                const targetData = normalized.getChannelData(channel);
                for (let i = 0; i < buffer.length; i++) {
                    targetData[i] = sourceData[i] * gain;
                }
            }
            
            return normalized;
        }
        
        async function concatenateWithSuffix(userBuffer) {
            try {
                const select = document.getElementById('suffixSelect');
                const selectedSuffix = select.value;
                const suffixBuffer = suffixBuffers[selectedSuffix];
                
                if (!suffixBuffer) {
                    throw new Error('Suffixe non charg√©: ' + selectedSuffix);
                }
                
                document.getElementById('debugNormalization').textContent = 'En cours...';
                const normalizedUser = normalizeBuffer(userBuffer);
                const normalizedSuffix = normalizeBuffer(suffixBuffer);
                document.getElementById('debugNormalization').textContent = '‚úÖ OK';
                
                document.getElementById('debugCrossfade').textContent = 'En cours...';
                const concatenatedBuffer = concatenateWithCrossfade(normalizedUser, normalizedSuffix);
                document.getElementById('debugCrossfade').textContent = '‚úÖ OK';
                
                document.getElementById('debugFinalDuration').textContent = 
                    concatenatedBuffer.duration.toFixed(2) + 's';
                
                lastConcatenatedBlob = await audioBufferToWavBlob(concatenatedBuffer);
                
                const audioPlayer = document.getElementById('audioPlayer');
                audioPlayer.src = URL.createObjectURL(lastConcatenatedBlob);
                document.getElementById('audioPlayerSection').classList.remove('hidden');
                
                updateStatus('processing', 'ü§ñ Reconnaissance Whisper en cours...');
                
                await recognizeAudio();
                
            } catch (error) {
                console.error('Erreur concat√©nation:', error);
                updateStatus('error', '‚ùå Erreur: ' + error.message);
                document.getElementById('recordBtn').disabled = false;
            }
        }
        
        function concatenateWithCrossfade(buffer1, buffer2) {
            const sampleRate = buffer1.sampleRate;
            const crossfadeSamples = Math.floor(CROSSFADE_DURATION * sampleRate);
            const numberOfChannels = Math.min(buffer1.numberOfChannels, buffer2.numberOfChannels);
            const totalLength = buffer1.length + buffer2.length - crossfadeSamples;
            
            const result = audioContext.createBuffer(numberOfChannels, totalLength, sampleRate);
            
            for (let channel = 0; channel < numberOfChannels; channel++) {
                const output = result.getChannelData(channel);
                const input1 = buffer1.getChannelData(channel);
                const input2 = buffer2.getChannelData(channel);
                
                for (let i = 0; i < buffer1.length - crossfadeSamples; i++) {
                    output[i] = input1[i];
                }
                
                const crossfadeStart = buffer1.length - crossfadeSamples;
                for (let i = 0; i < crossfadeSamples; i++) {
                    const ratio = i / crossfadeSamples;
                    const sample1 = input1[crossfadeStart + i];
                    const sample2 = input2[i];
                    output[crossfadeStart + i] = sample1 * (1 - ratio) + sample2 * ratio;
                }
                
                for (let i = crossfadeSamples; i < buffer2.length; i++) {
                    output[buffer1.length - crossfadeSamples + i] = input2[i];
                }
            }
            
            return result;
        }
        
        async function recognizeAudio() {
            try {
                document.getElementById('debugRecognition').textContent = 'Transcription...';
                
                const select = document.getElementById('suffixSelect');
                const expectedWord = select.options[select.selectedIndex].getAttribute('data-word');
                const expectedRomaji = select.options[select.selectedIndex].getAttribute('data-romaji');
                
                // Utiliser Whisper
                const transcript = await window.recognizeWithWhisper(lastConcatenatedBlob);
                
                document.getElementById('debugRecognition').textContent = 
                    `‚úÖ "${transcript}"`;
                
                document.getElementById('recognizedText').textContent = transcript;
                
                // Comparer (en hiragana et romaji)
                const cleanTranscript = transcript.trim().toLowerCase();
                const isCorrect = cleanTranscript === expectedWord || 
                                cleanTranscript === expectedRomaji ||
                                cleanTranscript.includes(expectedWord) || 
                                cleanTranscript.includes(expectedRomaji) ||
                                expectedWord.includes(cleanTranscript);
                
                if (isCorrect) {
                    document.getElementById('comparisonResult').textContent = '‚úÖ CORRECT !';
                    document.getElementById('comparisonResult').style.color = '#28a745';
                    updateStatus('success', '‚úÖ Mot reconnu !');
                } else {
                    document.getElementById('comparisonResult').textContent = 
                        `‚ùå Attendu: ${expectedWord} (${expectedRomaji})`;
                    document.getElementById('comparisonResult').style.color = '#dc3545';
                    updateStatus('error', '‚ùå Mot non reconnu');
                }
                
                document.getElementById('recognitionResult').classList.remove('hidden');
                document.getElementById('recordBtn').disabled = false;
                
            } catch (error) {
                console.error('Erreur reconnaissance:', error);
                document.getElementById('debugRecognition').textContent = 
                    `‚ùå Erreur: ${error.message}`;
                updateStatus('error', '‚ùå Erreur reconnaissance');
                document.getElementById('recordBtn').disabled = false;
            }
        }
        
        async function audioBufferToWavBlob(audioBuffer) {
            const numberOfChannels = audioBuffer.numberOfChannels;
            const length = audioBuffer.length * numberOfChannels * 2;
            const buffer = new ArrayBuffer(44 + length);
            const view = new DataView(buffer);
            const channels = [];
            let offset = 0;
            let pos = 0;
            
            const setUint16 = (data) => {
                view.setUint16(pos, data, true);
                pos += 2;
            };
            const setUint32 = (data) => {
                view.setUint32(pos, data, true);
                pos += 4;
            };
            
            setUint32(0x46464952);
            setUint32(length + 36);
            setUint32(0x45564157);
            setUint32(0x20746d66);
            setUint32(16);
            setUint16(1);
            setUint16(numberOfChannels);
            setUint32(audioBuffer.sampleRate);
            setUint32(audioBuffer.sampleRate * numberOfChannels * 2);
            setUint16(numberOfChannels * 2);
            setUint16(16);
            setUint32(0x61746164);
            setUint32(length);
            
            for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                channels.push(audioBuffer.getChannelData(i));
            }
            
            offset = 44;
            for (let i = 0; i < audioBuffer.length; i++) {
                for (let channel = 0; channel < numberOfChannels; channel++) {
                    let sample = Math.max(-1, Math.min(1, channels[channel][i]));
                    sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                    view.setInt16(offset, sample, true);
                    offset += 2;
                }
            }
            
            return new Blob([buffer], { type: 'audio/wav' });
        }
        
        function downloadAudio() {
            if (!lastConcatenatedBlob) {
                alert('‚ùå Aucun audio');
                return;
            }
            
            const suffix = document.getElementById('suffixSelect').value;
            const url = URL.createObjectURL(lastConcatenatedBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `test_${suffix}_${Date.now()}.wav`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
        
        function resetTest() {
            location.reload();
        }
        
        function updateStatus(type, message) {
            const status = document.getElementById('statusDisplay');
            status.className = `status ${type}`;
            status.textContent = message;
        }
        
        document.getElementById('suffixSelect').addEventListener('change', (e) => {
            const option = e.target.options[e.target.selectedIndex];
            document.getElementById('debugSuffix').textContent = e.target.value;
            document.getElementById('debugExpectedWord').textContent = option.getAttribute('data-word');
            document.getElementById('debugRomaji').textContent = option.getAttribute('data-romaji');
        });
        
        window.addEventListener('load', init);
    </script>
</body>
</html>


